# Config

## What is the Purpose of Config?

Configs serve as the **centralized configuration management layer** that provides hierarchical, validated, and environment-specific configuration for pipeline components. They represent the evolution from scattered configuration parameters to a unified, intelligent configuration system.

## Core Purpose

Configs provide **centralized configuration management** that:

1. **Hierarchical Configuration** - Support inheritance and composition patterns
2. **Environment-Specific Overrides** - Enable dev/staging/prod configurations
3. **Validation and Type Safety** - Ensure configuration correctness at creation time
4. **Template and Defaults** - Provide sensible defaults with customization points
5. **Integration Bridge** - Connect high-level settings to low-level implementation details

## Key Features

### 1. Hierarchical Configuration

Configs support inheritance and composition for maximum reusability:

```python
# Base configuration with common settings
class BaseStepConfig(ConfigBase):
    """Base configuration for all pipeline steps"""
    
    def __init__(self):
        self.role = "arn:aws:iam::123456789012:role/SageMakerRole"
        self.tags = {"Project": "MLPipeline", "Environment": "dev"}
        self.retry_policies = [StepRetryPolicy(exception_types=[StepExceptionTypeEnum.SERVICE_FAULT])]

# Specialized configuration inheriting from base
class TrainingStepConfig(BaseStepConfig):
    """Configuration for training steps"""
    
    def __init__(self):
        super().__init__()
        self.instance_type = "ml.m5.xlarge"
        self.instance_count = 1
        self.max_runtime_in_seconds = 3600
        self.use_spot_instances = False

# Specific implementation configuration
class XGBoostTrainingStepConfig(TrainingStepConfig):
    """Configuration for XGBoost training steps"""
    
    def __init__(self):
        super().__init__()
        self.framework_version = "1.5-1"
        self.entry_point = "train.py"
        self.source_dir = "src/training"
        self.hyperparameters = {
            "max_depth": 6,
            "eta": 0.3,
            "objective": "binary:logistic"
        }
```

### 2. Environment-Specific Overrides

Support different configurations for different environments:

```python
class EnvironmentConfig:
    """Environment-specific configuration overrides"""
    
    @staticmethod
    def get_config_for_environment(base_config: ConfigBase, environment: str):
        """Apply environment-specific overrides"""
        
        if environment == "dev":
            return EnvironmentConfig._apply_dev_overrides(base_config)
        elif environment == "staging":
            return EnvironmentConfig._apply_staging_overrides(base_config)
        elif environment == "prod":
            return EnvironmentConfig._apply_prod_overrides(base_config)
        else:
            return base_config
    
    @staticmethod
    def _apply_dev_overrides(config):
        """Development environment overrides"""
        config.instance_type = "ml.t3.medium"  # Smaller instances for dev
        config.max_runtime_in_seconds = 1800   # Shorter timeouts
        config.use_spot_instances = True       # Cost optimization
        config.tags["Environment"] = "dev"
        return config
    
    @staticmethod
    def _apply_prod_overrides(config):
        """Production environment overrides"""
        config.instance_type = "ml.m5.2xlarge"  # Larger instances for prod
        config.max_runtime_in_seconds = 7200    # Longer timeouts
        config.use_spot_instances = False       # Reliability over cost
        config.tags["Environment"] = "prod"
        config.retry_policies.append(
            StepRetryPolicy(exception_types=[StepExceptionTypeEnum.THROTTLING])
        )
        return config

# Usage
base_config = XGBoostTrainingStepConfig()
dev_config = EnvironmentConfig.get_config_for_environment(base_config, "dev")
prod_config = EnvironmentConfig.get_config_for_environment(base_config, "prod")
```

### 3. Validation and Type Safety

Configs provide validation at creation time to catch errors early:

```python
class ValidatedConfig(ConfigBase):
    """Configuration with comprehensive validation"""
    
    def __init__(self, instance_type: str, hyperparameters: Dict[str, Any]):
        self.instance_type = instance_type
        self.hyperparameters = hyperparameters
        
        # Validate immediately upon creation
        self.validate_configuration()
    
    def validate_configuration(self):
        """Validate configuration parameters"""
        errors = []
        
        # Validate instance type
        valid_instance_types = ["ml.t3.medium", "ml.m5.large", "ml.m5.xlarge", "ml.m5.2xlarge"]
        if self.instance_type not in valid_instance_types:
            errors.append(f"Invalid instance_type: {self.instance_type}. Must be one of: {valid_instance_types}")
        
        # Validate hyperparameters
        if "max_depth" in self.hyperparameters:
            max_depth = self.hyperparameters["max_depth"]
            if not isinstance(max_depth, int) or max_depth < 1 or max_depth > 20:
                errors.append("max_depth must be an integer between 1 and 20")
        
        if "eta" in self.hyperparameters:
            eta = self.hyperparameters["eta"]
            if not isinstance(eta, (int, float)) or eta <= 0 or eta > 1:
                errors.append("eta must be a number between 0 and 1")
        
        if errors:
            raise ConfigurationError(f"Configuration validation failed: {errors}")
    
    def merge_with(self, other_config: 'ValidatedConfig'):
        """Merge with another configuration, validating the result"""
        merged = ValidatedConfig(
            instance_type=other_config.instance_type or self.instance_type,
            hyperparameters={**self.hyperparameters, **other_config.hyperparameters}
        )
        return merged
```

### 4. Template and Defaults

Provide sensible defaults with clear customization points:

```python
class TemplateConfig:
    """Template configurations for common use cases"""
    
    @staticmethod
    def quick_prototype_config():
        """Fast, cheap configuration for prototyping"""
        return XGBoostTrainingStepConfig(
            instance_type="ml.t3.medium",
            instance_count=1,
            max_runtime_in_seconds=1800,
            use_spot_instances=True,
            hyperparameters={
                "max_depth": 3,
                "eta": 0.3,
                "num_round": 100
            }
        )
    
    @staticmethod
    def production_config():
        """Robust configuration for production workloads"""
        return XGBoostTrainingStepConfig(
            instance_type="ml.m5.2xlarge",
            instance_count=1,
            max_runtime_in_seconds=7200,
            use_spot_instances=False,
            hyperparameters={
                "max_depth": 6,
                "eta": 0.1,
                "num_round": 1000,
                "early_stopping_rounds": 50
            },
            retry_policies=[
                StepRetryPolicy(exception_types=[StepExceptionTypeEnum.SERVICE_FAULT]),
                StepRetryPolicy(exception_types=[StepExceptionTypeEnum.THROTTLING])
            ]
        )
    
    @staticmethod
    def hyperparameter_tuning_config():
        """Configuration optimized for hyperparameter tuning"""
        return XGBoostTrainingStepConfig(
            instance_type="ml.m5.large",
            instance_count=1,
            max_runtime_in_seconds=3600,
            use_spot_instances=True,
            hyperparameters={
                "max_depth": 6,
                "eta": 0.3,
                "num_round": 500
            },
            # Enable early stopping for tuning efficiency
            early_stopping_patience=10
        )

# Usage
prototype_config = TemplateConfig.quick_prototype_config()
production_config = TemplateConfig.production_config()
tuning_config = TemplateConfig.hyperparameter_tuning_config()
```

### 5. Integration Bridge

Connect high-level settings to low-level implementation details:

```python
class IntegrationConfig(ConfigBase):
    """Configuration that bridges high-level intent to implementation"""
    
    def __init__(self, performance_tier: str = "balanced"):
        self.performance_tier = performance_tier
        self._apply_performance_tier_settings()
    
    def _apply_performance_tier_settings(self):
        """Apply settings based on performance tier"""
        
        if self.performance_tier == "cost_optimized":
            self.instance_type = "ml.t3.medium"
            self.use_spot_instances = True
            self.max_runtime_in_seconds = 1800
            self.hyperparameters = {"max_depth": 3, "eta": 0.3, "num_round": 100}
            
        elif self.performance_tier == "balanced":
            self.instance_type = "ml.m5.large"
            self.use_spot_instances = True
            self.max_runtime_in_seconds = 3600
            self.hyperparameters = {"max_depth": 6, "eta": 0.2, "num_round": 500}
            
        elif self.performance_tier == "performance_optimized":
            self.instance_type = "ml.m5.2xlarge"
            self.use_spot_instances = False
            self.max_runtime_in_seconds = 7200
            self.hyperparameters = {"max_depth": 8, "eta": 0.1, "num_round": 1000}
            
        else:
            raise ValueError(f"Unknown performance tier: {self.performance_tier}")
    
    def to_dict(self):
        """Convert configuration to dictionary for serialization"""
        return {
            "performance_tier": self.performance_tier,
            "instance_type": self.instance_type,
            "use_spot_instances": self.use_spot_instances,
            "max_runtime_in_seconds": self.max_runtime_in_seconds,
            "hyperparameters": self.hyperparameters
        }
    
    @classmethod
    def from_dict(cls, config_dict: Dict[str, Any]):
        """Create configuration from dictionary"""
        config = cls(performance_tier=config_dict["performance_tier"])
        # Override with any explicit settings
        for key, value in config_dict.items():
            if key != "performance_tier":
                setattr(config, key, value)
        return config
```

## Integration with Other Components

### With Step Builders

[Step Builders](step_builder.md) use dependency injection pattern with configs:

```python
class XGBoostTrainingStepBuilder(BuilderStepBase):
    def __init__(self, config: XGBoostTrainingStepConfig):
        self.config = config  # Injected configuration
        super().__init__()
    
    def build_step(self, inputs):
        # Use configuration to create estimator
        estimator = XGBoost(
            entry_point=self.config.entry_point,
            framework_version=self.config.framework_version,
            instance_type=self.config.instance_type,
            hyperparameters=self.config.hyperparameters,
            role=self.config.role
        )
        
        return TrainingStep(
            name=self.step_name,
            estimator=estimator,
            inputs=self._create_inputs(inputs)
        )
```

### With Smart Proxies

[Smart Proxies](smart_proxy.md) use configs for intelligent defaults and customization:

```python
class SmartXGBoostTraining:
    def __init__(self, config: XGBoostTrainingStepConfig = None):
        self.config = config or TemplateConfig.balanced_config()
        self.builder = XGBoostTrainingStepBuilder(self.config)
    
    def with_performance_tier(self, tier: str):
        """Fluent interface for performance configuration"""
        self.config = IntegrationConfig(performance_tier=tier)
        self.builder = XGBoostTrainingStepBuilder(self.config)
        return self
    
    def with_custom_hyperparameters(self, **hyperparameters):
        """Fluent interface for hyperparameter customization"""
        self.config.hyperparameters.update(hyperparameters)
        return self
```

### With Fluent APIs

[Fluent APIs](fluent_api.md) use configs to provide natural configuration interfaces:

```python
# Natural language configuration through fluent API
training_step = (Pipeline("fraud-detection")
    .train_xgboost()
    .with_performance_tier("cost_optimized")
    .with_hyperparameters(max_depth=4, eta=0.2)
    .with_early_stopping(patience=10)
    .on_spot_instances()
    .with_timeout_minutes(30))
```

## Strategic Value

Configs provide:

1. **Configuration Centralization**: Single source of truth for all settings
2. **Environment Flexibility**: Easy adaptation to different deployment environments
3. **Validation and Safety**: Early error detection through validation
4. **Template Reusability**: Common patterns can be shared and customized
5. **Integration Simplification**: Bridge between high-level intent and implementation
6. **Maintainability**: Changes to configuration logic isolated and manageable

## Example Usage

```python
# Basic configuration creation
config = XGBoostTrainingStepConfig(
    instance_type="ml.m5.xlarge",
    hyperparameters={"max_depth": 6, "eta": 0.3}
)

# Environment-specific configuration
dev_config = EnvironmentConfig.get_config_for_environment(config, "dev")
prod_config = EnvironmentConfig.get_config_for_environment(config, "prod")

# Template-based configuration
prototype_config = TemplateConfig.quick_prototype_config()

# High-level configuration
performance_config = IntegrationConfig(performance_tier="performance_optimized")

# Configuration merging and validation
merged_config = config.merge_with(performance_config)
merged_config.validate_configuration()

# Serialization for persistence
config_dict = merged_config.to_dict()
restored_config = IntegrationConfig.from_dict(config_dict)
```

Configs form the **configuration management foundation** that enables flexible, validated, and environment-aware configuration of pipeline components while maintaining clean separation between configuration logic and implementation details.
