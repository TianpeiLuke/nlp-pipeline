---
tags:
  - design
  - implementation
  - pipeline_deps
  - registry_management
keywords:
  - registry manager
  - multi-registry coordination
  - context isolation
  - specification management
  - registry lifecycle
  - thread-safety
  - registry orchestration
topics:
  - registry management
  - context coordination
  - pipeline isolation
  - multi-registry architecture
language: python
date of note: 2025-07-31
---

# Registry Manager

## What is the Purpose of Registry Manager?

Registry Manager serves as the **centralized orchestration layer** for multiple specification registries, enabling coordinated management of context-specific registries while maintaining complete isolation between them. It represents the evolution from manual registry coordination to intelligent, automated multi-registry management.

## Core Purpose

Registry Manager provides a **unified multi-registry coordination system** that enables:

1. **Multi-Context Management** - Coordinate multiple isolated registries across different pipelines and contexts
2. **Lifecycle Orchestration** - Manage creation, cleanup, and lifecycle of registry instances
3. **Simplified API** - Provide convenient access functions that hide complexity
4. **Backward Compatibility** - Maintain compatibility with existing code while enabling new patterns
5. **Global Coordination** - Enable system-wide registry management and monitoring

## Key Features

### 1. Multi-Registry Coordination

Centralized management of multiple isolated registries:

```python
from src.pipeline_deps import registry_manager, get_registry

# Create multiple registries for different contexts
training_registry = get_registry("training_pipeline")
inference_registry = get_registry("inference_pipeline")
testing_registry = get_registry("unit_tests")

# Each registry is completely isolated
training_registry.register("data_loading", TRAINING_DATA_SPEC)
inference_registry.register("data_loading", INFERENCE_DATA_SPEC)
testing_registry.register("data_loading", TEST_DATA_SPEC)

# Manager coordinates all registries
all_contexts = registry_manager.list_contexts()
print(f"Managing {len(all_contexts)} registry contexts: {all_contexts}")
# Output: Managing 3 registry contexts: ['training_pipeline', 'inference_pipeline', 'unit_tests']
```

### 2. Intelligent Registry Lifecycle

Automatic creation and cleanup of registry instances:

```python
# Registries are created on-demand
pipeline_registry = get_registry("new_pipeline")  # Creates if doesn't exist
existing_registry = get_registry("new_pipeline")  # Returns existing instance

# Same instance is returned
assert pipeline_registry is existing_registry

# Optional creation control
maybe_registry = get_registry("nonexistent", create_if_missing=False)
assert maybe_registry is None  # Returns None instead of creating

# Cleanup when no longer needed
success = registry_manager.clear_context("old_pipeline")
print(f"Cleanup successful: {success}")

# Bulk cleanup
registry_manager.clear_all_contexts()
print(f"Remaining contexts: {len(registry_manager.list_contexts())}")  # 0
```

### 3. Context Statistics and Monitoring

Comprehensive monitoring and statistics across all registries:

```python
# Get detailed statistics for all contexts
stats = registry_manager.get_context_stats()

for context_name, context_stats in stats.items():
    print(f"Context: {context_name}")
    print(f"  Steps: {context_stats['step_count']}")
    print(f"  Types: {context_stats['step_type_count']}")
    print(f"  Registry: {context_stats['registry_type']}")
    print()

# Example output:
# Context: training_pipeline
#   Steps: 5
#   Types: 4
#   Registry: SpecificationRegistry
#
# Context: inference_pipeline
#   Steps: 3
#   Types: 3
#   Registry: SpecificationRegistry
```

### 4. Convenient Access Functions

Simplified API that hides complexity:

```python
from src.pipeline_deps import (
    get_registry, get_pipeline_registry, get_default_registry,
    list_contexts, clear_context, get_context_stats
)

# Primary access function
registry = get_registry("my_pipeline")

# Backward compatibility functions
pipeline_registry = get_pipeline_registry("my_pipeline")  # Same as get_registry
default_registry = get_default_registry()  # Gets "default" context

# Convenience functions
contexts = list_contexts()
stats = get_context_stats()
cleared = clear_context("old_pipeline")

# All functions work with the same underlying manager
assert get_registry("test") is get_pipeline_registry("test")
```

### 5. Global Instance Management

Thread-safe global coordination:

```python
# Global manager instance is automatically created
from src.pipeline_deps import registry_manager

# Thread-safe operations
registry1 = registry_manager.get_registry("context1")
registry2 = registry_manager.get_registry("context2")

# Manager state is consistent across the application
print(f"Manager has {len(registry_manager.list_contexts())} contexts")

# Global cleanup when needed (e.g., in tests)
registry_manager.clear_all_contexts()
```

## Integration with Other Components

### With Specification Registry

Registry Manager orchestrates SpecificationRegistry instances:

```python
from src.pipeline_deps import get_registry, SpecificationRegistry

# Manager creates and returns SpecificationRegistry instances
registry = get_registry("my_pipeline")
assert isinstance(registry, SpecificationRegistry)

# Each registry maintains its context
assert registry.context_name == "my_pipeline"

# Manager tracks all created registries
all_registries = [get_registry(ctx) for ctx in list_contexts()]
print(f"Created {len(all_registries)} registries")
```

### With Pipeline Builders

Seamless integration with pipeline construction:

```python
from src.pipeline_deps import integrate_with_pipeline_builder

@integrate_with_pipeline_builder
class TrainingPipelineBuilder:
    def __init__(self, config):
        self.base_config = config
        # self.registry is automatically set by decorator
        # Uses get_registry(config.pipeline_name) internally
    
    def build_pipeline(self):
        # Registry is automatically available
        self.registry.register("data_loading", DATA_LOADING_SPEC)
        self.registry.register("training", TRAINING_SPEC)
        
        # Build pipeline using registry
        return self.create_pipeline_steps()

# Builder automatically gets the right registry
builder = TrainingPipelineBuilder(config)
# builder.registry is get_registry(config.pipeline_name)
```

### With Dependency Resolver

Registry Manager enables resolver coordination:

```python
from src.pipeline_deps import UnifiedDependencyResolver

# Get registry through manager
registry = get_registry("training_pipeline")

# Create resolver with managed registry
resolver = UnifiedDependencyResolver(registry)

# Register specifications through manager
registry.register("data_loading", DATA_LOADING_SPEC)
registry.register("preprocessing", PREPROCESSING_SPEC)

# Resolve dependencies
resolved = resolver.resolve_all_dependencies(["data_loading", "preprocessing"])

# Manager tracks all registry usage
stats = get_context_stats()
print(f"Training pipeline has {stats['training_pipeline']['step_count']} steps")
```

### With Testing Framework

Perfect isolation for testing:

```python
import unittest
from src.pipeline_deps import get_registry, clear_context

class TestPipelineComponents(unittest.TestCase):
    def setUp(self):
        """Create isolated test registry."""
        self.test_registry = get_registry("test_context")
        
    def tearDown(self):
        """Clean up test registry."""
        clear_context("test_context")
    
    def test_component_integration(self):
        """Test components with isolated registry."""
        # Register test specifications
        self.test_registry.register("test_step", TEST_SPEC)
        
        # Test functionality
        spec = self.test_registry.get_specification("test_step")
        self.assertIsNotNone(spec)
        
        # Registry is automatically cleaned up in tearDown
        # No impact on other tests or production code
```

## Strategic Value

Registry Manager enables:

1. **Simplified Architecture**: Hide complexity behind convenient functions
2. **Multi-Pipeline Support**: Enable multiple pipelines in the same application
3. **Testing Isolation**: Perfect isolation for unit and integration tests
4. **Backward Compatibility**: Existing code continues to work unchanged
5. **Monitoring and Debugging**: Comprehensive visibility into registry usage
6. **Resource Management**: Automatic cleanup and lifecycle management
7. **Thread Safety**: Safe concurrent access to registries

## Architecture Benefits

### Centralized Coordination Pattern

The registry manager pattern provides several architectural advantages:

```python
class RegistryManager:
    """Centralized manager for multiple specification registries."""
    
    def __init__(self):
        self._registries: Dict[str, SpecificationRegistry] = {}
        self._lock = threading.Lock()  # Thread safety
    
    def get_registry(self, context_name: str, create_if_missing: bool = True) -> Optional[SpecificationRegistry]:
        """Get or create registry for context."""
        with self._lock:
            if context_name not in self._registries and create_if_missing:
                self._registries[context_name] = SpecificationRegistry(context_name)
            return self._registries.get(context_name)
    
    def clear_context(self, context_name: str) -> bool:
        """Remove registry for context."""
        with self._lock:
            return self._registries.pop(context_name, None) is not None
```

### Benefits:

1. **Single Point of Control**: All registry operations go through manager
2. **Thread Safety**: Concurrent access is properly synchronized
3. **Resource Tracking**: Manager knows about all created registries
4. **Lifecycle Management**: Automatic creation and cleanup
5. **Consistent API**: Uniform interface across all registry operations
6. **Extensible**: Easy to add new management features

## Example Usage

### Basic Multi-Registry Management

```python
from src.pipeline_deps import get_registry, list_contexts, get_context_stats

# Create registries for different purposes
training_registry = get_registry("fraud_detection_training")
inference_registry = get_registry("fraud_detection_inference")
testing_registry = get_registry("unit_tests")

# Register different specifications in each
training_registry.register("data_loading", TRAINING_DATA_LOADING_SPEC)
training_registry.register("feature_engineering", FEATURE_ENGINEERING_SPEC)
training_registry.register("model_training", XGBOOST_TRAINING_SPEC)

inference_registry.register("model_loading", MODEL_LOADING_SPEC)
inference_registry.register("batch_transform", BATCH_TRANSFORM_SPEC)

testing_registry.register("mock_data_source", MOCK_DATA_SOURCE_SPEC)
testing_registry.register("test_processor", TEST_PROCESSOR_SPEC)

# Monitor all registries
contexts = list_contexts()
print(f"Active contexts: {contexts}")

stats = get_context_stats()
for context, info in stats.items():
    print(f"{context}: {info['step_count']} steps, {info['step_type_count']} types")

# Example output:
# Active contexts: ['fraud_detection_training', 'fraud_detection_inference', 'unit_tests']
# fraud_detection_training: 3 steps, 3 types
# fraud_detection_inference: 2 steps, 2 types
# unit_tests: 2 steps, 2 types
```

### Advanced Pipeline Builder Integration

```python
from src.pipeline_deps import integrate_with_pipeline_builder, get_registry

@integrate_with_pipeline_builder
class MultiEnvironmentPipelineBuilder:
    def __init__(self, config):
        self.base_config = config
        self.environment = config.environment  # 'dev', 'staging', 'prod'
        # self.registry is automatically set to get_registry(f"{config.pipeline_name}_{environment}")
    
    def build_training_pipeline(self):
        """Build environment-specific training pipeline."""
        # Register environment-specific specifications
        if self.environment == "dev":
            self.registry.register("data_loading", DEV_DATA_LOADING_SPEC)
            self.registry.register("training", FAST_TRAINING_SPEC)
        elif self.environment == "prod":
            self.registry.register("data_loading", PROD_DATA_LOADING_SPEC)
            self.registry.register("training", PRODUCTION_TRAINING_SPEC)
        
        # Build pipeline using environment-specific registry
        return self.create_pipeline_steps()
    
    def get_environment_stats(self):
        """Get statistics for this environment."""
        context_name = f"{self.base_config.pipeline_name}_{self.environment}"
        stats = get_context_stats()
        return stats.get(context_name, {})

# Create builders for different environments
dev_config = Config(pipeline_name="fraud_detection", environment="dev")
prod_config = Config(pipeline_name="fraud_detection", environment="prod")

dev_builder = MultiEnvironmentPipelineBuilder(dev_config)
prod_builder = MultiEnvironmentPipelineBuilder(prod_config)

# Each builder gets its own isolated registry
dev_pipeline = dev_builder.build_training_pipeline()
prod_pipeline = prod_builder.build_training_pipeline()

# Registries are completely isolated
dev_stats = dev_builder.get_environment_stats()
prod_stats = prod_builder.get_environment_stats()

print(f"Dev environment: {dev_stats}")
print(f"Prod environment: {prod_stats}")
```

### Testing with Registry Isolation

```python
import unittest
from src.pipeline_deps import get_registry, clear_context, list_contexts

class TestRegistryManager(unittest.TestCase):
    def setUp(self):
        """Set up isolated test environment."""
        # Clear any existing test contexts
        for context in list_contexts():
            if context.startswith("test_"):
                clear_context(context)
        
        # Create test registries
        self.test_registry = get_registry("test_main")
        self.helper_registry = get_registry("test_helper")
    
    def tearDown(self):
        """Clean up test environment."""
        clear_context("test_main")
        clear_context("test_helper")
    
    def test_registry_isolation(self):
        """Test that registries are properly isolated."""
        # Register different specs in each registry
        self.test_registry.register("step1", TEST_SPEC_1)
        self.helper_registry.register("step2", TEST_SPEC_2)
        
        # Verify isolation
        self.assertIn("step1", self.test_registry.list_step_names())
        self.assertNotIn("step1", self.helper_registry.list_step_names())
        
        self.assertIn("step2", self.helper_registry.list_step_names())
        self.assertNotIn("step2", self.test_registry.list_step_names())
    
    def test_manager_coordination(self):
        """Test manager coordination features."""
        # Register specs in both registries
        self.test_registry.register("main_step", TEST_SPEC_1)
        self.helper_registry.register("helper_step", TEST_SPEC_2)
        
        # Check manager statistics
        stats = get_context_stats()
        
        self.assertIn("test_main", stats)
        self.assertIn("test_helper", stats)
        
        self.assertEqual(stats["test_main"]["step_count"], 1)
        self.assertEqual(stats["test_helper"]["step_count"], 1)
    
    def test_cleanup_functionality(self):
        """Test registry cleanup."""
        # Create and populate registry
        temp_registry = get_registry("test_temp")
        temp_registry.register("temp_step", TEST_SPEC_1)
        
        # Verify it exists
        self.assertIn("test_temp", list_contexts())
        
        # Clean it up
        success = clear_context("test_temp")
        self.assertTrue(success)
        
        # Verify it's gone
        self.assertNotIn("test_temp", list_contexts())
        
        # Cleanup non-existent context
        success = clear_context("nonexistent")
        self.assertFalse(success)

class TestBackwardCompatibility(unittest.TestCase):
    def test_backward_compatible_functions(self):
        """Test that old function names still work."""
        from src.pipeline_deps import get_pipeline_registry, get_default_registry
        
        # Old function names should work
        pipeline_registry = get_pipeline_registry("test_pipeline")
        default_registry = get_default_registry()
        
        # Should return SpecificationRegistry instances
        from src.pipeline_deps import SpecificationRegistry
        self.assertIsInstance(pipeline_registry, SpecificationRegistry)
        self.assertIsInstance(default_registry, SpecificationRegistry)
        
        # Should be equivalent to new functions
        new_pipeline_registry = get_registry("test_pipeline")
        new_default_registry = get_registry("default")
        
        self.assertIs(pipeline_registry, new_pipeline_registry)
        self.assertIs(default_registry, new_default_registry)
    
    def tearDown(self):
        """Clean up test registries."""
        clear_context("test_pipeline")
        clear_context("default")
```

### Production Monitoring and Management

```python
from src.pipeline_deps import get_context_stats, list_contexts, registry_manager

def monitor_registry_usage():
    """Monitor registry usage across the application."""
    stats = get_context_stats()
    
    print("Registry Usage Report")
    print("=" * 50)
    
    total_contexts = len(stats)
    total_steps = sum(info['step_count'] for info in stats.values())
    total_types = sum(info['step_type_count'] for info in stats.values())
    
    print(f"Total Contexts: {total_contexts}")
    print(f"Total Steps: {total_steps}")
    print(f"Total Step Types: {total_types}")
    print()
    
    for context_name, info in stats.items():
        print(f"Context: {context_name}")
        print(f"  Steps: {info['step_count']}")
        print(f"  Types: {info['step_type_count']}")
        print(f"  Registry Type: {info['registry_type']}")
        print()

def cleanup_old_contexts(max_age_hours=24):
    """Clean up old test contexts (example)."""
    import time
    
    contexts = list_contexts()
    cleaned = 0
    
    for context in contexts:
        if context.startswith("test_") or context.startswith("temp_"):
            # In real implementation, check creation time
            # For demo, just clean up test contexts
            if clear_context(context):
                cleaned += 1
                print(f"Cleaned up context: {context}")
    
    print(f"Cleaned up {cleaned} old contexts")

# Run monitoring
monitor_registry_usage()

# Periodic cleanup (in real application, this might be scheduled)
cleanup_old_contexts()
```

## Migration from Direct Registry Usage

### Old Pattern (Direct Registry Creation)
```python
# Old direct registry creation
from src.pipeline_deps import SpecificationRegistry

# Manual registry management
training_registry = SpecificationRegistry("training")
inference_registry = SpecificationRegistry("inference")

# Manual cleanup required
del training_registry
del inference_registry
```

### New Pattern (Manager-Coordinated)
```python
# New manager-coordinated approach
from src.pipeline_deps import get_registry, clear_context

# Manager handles creation and tracking
training_registry = get_registry("training")
inference_registry = get_registry("inference")

# Automatic cleanup available
clear_context("training")
clear_context("inference")

# Or use convenience functions for common patterns
from src.pipeline_deps import get_pipeline_registry
pipeline_registry = get_pipeline_registry("my_pipeline")
```

---

Registry Manager represents the **centralized orchestration layer** that enables sophisticated multi-registry architectures while maintaining simplicity and backward compatibility. It works seamlessly with [Specification Registry](specification_registry.md) for storage and [Dependency Resolver](dependency_resolver.md) for intelligent matching, providing the coordination backbone for scalable pipeline systems.
